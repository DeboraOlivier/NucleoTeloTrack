{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a test run**: \n",
    "- In \"Kernel\" select \"Restart and Clear Output\"\n",
    "- then use Shift + Enter to run the individual cells after setting them up\n",
    "\n",
    "**if all cells are correctly set up**: just press \"Run\"\n",
    "\n",
    "\n",
    "This notebook processes the output from CellProfiler (CSV table with the track data & measurements) and aligns the tracks according to a reference time.\n",
    "\n",
    "The notebook includes step-by-step processing of tracks tabels obtained from CellProfiler. \n",
    "Functions used to process the tracks are written within the module trackprocessor.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import to_agraph \n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "from functools import partial\n",
    "import pathos.pools as pp\n",
    "import dill\n",
    "\n",
    "import trackprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(trackprocessor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff() # turn interactive plotting off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.max_open_warning': 0}) # ignore max plotted figures warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.settings['recurse'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: do not enclose the path string by a seperator (\"\\\" for Windows or \"/\" for Linux or MacOS)\n",
    "# Windows example: C:\\blabla\\blabla\n",
    "# Linux or MacOs example: /home/blabla/blabla\n",
    "base_input_path = r\"/media/mphan/Data/Perso/Phan/LOB/NucleoTeloTrack/2020-09_RUN3_CP4.0.3/siCTRL_20190524_Pos02_cl16\"\n",
    "base_output_path = r\"/media/mphan/Data/Perso/Phan/LOB/NucleoTeloTrack/Output3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading csv files from input folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb. of files: 3\n",
      "0 : /Image.csv\n",
      "1 : /Nuclei.csv\n",
      "2 : /Telomere.csv\n"
     ]
    }
   ],
   "source": [
    "# Create \"Movies\" subfolder\n",
    "base_output_spath = os.path.join(base_output_path,\"Movies\")\n",
    "if not os.path.exists(base_output_spath):\n",
    "    os.makedirs(base_output_spath)\n",
    "\n",
    "# Read all csv file from folder\n",
    "input_files = glob.glob(os.path.join(base_input_path,\"**/*.csv\"),recursive=True)\n",
    "print(\"nb. of files:\",len(input_files))\n",
    "[print(i,\":\",input_files[i].split(base_input_path)[1]) for i in range(len(input_files))];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State transistions labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State labels** are defined as the classification labels assigned by the CellProfiler pipeline.\n",
    "In our case, we used 5 labels: interphase, prophase, prometaphase, metaphase and anaphase.\n",
    "Each label will have a unique **state number** which will be use to define the **state transition** from one to the other using the **transition rule graph (section 2.3)**\n",
    "\n",
    "However, it is possible to have more than 5 labels and then change the transition rule graph accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interphase      1\n",
      "prophase        2\n",
      "prometaphase    3\n",
      "metaphase       4\n",
      "anaphase        5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define state transistions\n",
    "state_labels = [\"interphase\",\"prophase\",\"prometaphase\",\"metaphase\",\"anaphase\"]\n",
    "numbers = np.arange(len(state_labels))+1 # the number is assigned automatically in increasing order from 1\n",
    "state_numbers = pd.Series(index=state_labels,data=numbers)\n",
    "print(state_numbers);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transistion rule graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can define the authorized transitions. For instance/\n",
    "\n",
    "**interphase** can transition to **prophase** or **prometaphase** but not to other states.\n",
    "\n",
    "You can sequentially define all authorised transitions and review them in the graph that will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph with multiple directions\n",
    "G=nx.OrderedMultiDiGraph() # this graph type keeps order of input nodes\n",
    "\n",
    "# Add nodes\n",
    "G.add_nodes_from(state_labels);\n",
    "\n",
    "# Add self transistions\n",
    "G.add_edges_from(list(zip(state_labels,state_labels)));\n",
    "\n",
    "# Define transistion rules\n",
    "G.add_edges_from([(\"interphase\",item) for item in [\"prophase\",\"prometaphase\"]]);\n",
    "G.add_edges_from([(\"prophase\",item) for item in [\"prometaphase\",\"metaphase\"]]);\n",
    "G.add_edges_from([(\"prometaphase\",item) for item in [\"prophase\",\"metaphase\"]]);\n",
    "G.add_edges_from([(\"metaphase\",item) for item in [\"prometaphase\",\"anaphase\"]]);\n",
    "G.add_edges_from([(\"anaphase\",item) for item in [\"interphase\"]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fig\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw_networkx(G, pos=pos, ax=ax, width=1, arrowsize=20, \n",
    "                 min_source_margin=50, min_target_margin=50,\n",
    "                 node_shape=\"s\", node_color=\"none\")\n",
    "fig.savefig(os.path.join(base_output_path,\"transistion_rule.png\"))\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test remove transistion functions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "state_labels = [\"unknown\"] + state_labels\n",
    "print(state_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# add \"unknown\" state to G\n",
    "G.add_node(\"unknown\")\n",
    "G.add_edge(\"unknown\",\"unknown\");\n",
    "G.add_edges_from([(\"unknown\",item) for item in list(G.nodes)]);\n",
    "G.add_edges_from([(item,\"unknown\") for item in list(G.nodes)]);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# row = [1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,2,2,1,1,1,1,1,1,1]\n",
    "# row = [1,1,1,1,1,1,2,2,1,1,1,1,2,2,2,2,3,3,3,1,1,1,4,4]\n",
    "# row = [1,1,1,1,1,2,2,2,2,2,3,3,3,4,4,2,2]\n",
    "# row = [1,1,1,2,2,2,1,1,1]\n",
    "# row = [0,0,0,0,0,0]\n",
    "# row = [1,1,1,1,0,0,0,2,2,2,1,2,1]\n",
    "row = [2,2,2,1,2,1]\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "row = []\n",
    "super_state = [2,1,2,1]\n",
    "state_len = [3,1,1,1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trackprocessor.correct_transistion_row(row,G,state_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "icol = 0\n",
    "state_len = []\n",
    "sup_state_id = []\n",
    "count = 1\n",
    "while (icol < len(row)):\n",
    "    if((icol)==(len(row)-1)):\n",
    "        state_len.append(count)\n",
    "        sup_state_id.append(row[icol])\n",
    "    elif row[icol] == row[icol+1]:\n",
    "        count += 1\n",
    "    else:\n",
    "        state_len.append(count)\n",
    "        sup_state_id.append(row[icol])\n",
    "        count = 1\n",
    "    icol += 1\n",
    "    \n",
    "is_excluded = [False for _ in sup_state_id]\n",
    "\n",
    "print(sup_state_id)\n",
    "print(state_len)\n",
    "print(is_excluded)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "statelbl = state_labels\n",
    "iprev, icrr, inext = -1, 0, 1\n",
    "while((icrr < (len(sup_state_id)-1)) & (inext < len(sup_state_id))):\n",
    "\n",
    "    if iprev == -1:\n",
    "        prev_state_id = 0\n",
    "        prev_state_len = 0\n",
    "    else:\n",
    "        prev_state_id = sup_state_id[iprev]\n",
    "        prev_state_len = state_len[iprev]\n",
    "    \n",
    "    curr_state_id = sup_state_id[icrr]\n",
    "    curr_state_len = state_len[icrr]\n",
    "    \n",
    "    next_state_id = sup_state_id[inext]\n",
    "    next_state_len = state_len[inext]\n",
    "    \n",
    "    print(\"previous current state:\",prev_state_id,prev_state_len)\n",
    "    print(\"current state:\",curr_state_id,curr_state_len)\n",
    "    print(\"next state:\",next_state_id,next_state_len)\n",
    "    \n",
    "    if(G.has_edge(statelbl[curr_state_id],statelbl[next_state_id])==True):\n",
    "        iprev = icrr\n",
    "        icrr += 1\n",
    "        inext += 1\n",
    "    else:\n",
    "        if(G.has_edge(statelbl[prev_state_id],statelbl[next_state_id])==False):\n",
    "            is_excluded[inext] = True\n",
    "            inext += 1\n",
    "        else:\n",
    "            curr_state_score = prev_state_len + curr_state_len\n",
    "            next_state_score = prev_state_len + next_state_len\n",
    "            \n",
    "            print(curr_state_score)\n",
    "            print(next_state_score)\n",
    "            \n",
    "            if curr_state_score < next_state_score:\n",
    "                is_excluded[icrr] = True\n",
    "                icrr += 1\n",
    "                inext += 1\n",
    "            elif next_state_score < curr_state_score:\n",
    "                is_excluded[inext] = True\n",
    "                inext += 1\n",
    "            else:\n",
    "                curr_path_len = nx.shortest_path_length(G,statelbl[prev_state_id],statelbl[curr_state_id])\n",
    "                next_path_len = nx.shortest_path_length(G,statelbl[prev_state_id],statelbl[next_state_id])\n",
    "                if curr_path_len <= next_path_len:\n",
    "                    is_excluded[inext] = True\n",
    "                    inext += 1\n",
    "                else:\n",
    "                    is_excluded[icrr] = True\n",
    "                    icrr += 1\n",
    "                    inext += 1\n",
    "            \n",
    "print(row)\n",
    "\n",
    "row2 = []\n",
    "for item in zip(sup_state_id,state_len,is_excluded):\n",
    "    if item[2] == False:\n",
    "        row2 += [item[0] for _ in range(item[1])]\n",
    "    else:\n",
    "        row2 += [0 for _ in range(item[1])]\n",
    "print(row2)\n",
    "            \n",
    "print(sup_state_id)\n",
    "print(state_len)\n",
    "print(is_excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluded border conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 options to remove objects touching the border:\n",
    "1. **circle (percentage argument)**: for _CellProfiler version <4.0_, using parameters \"AreaShape_Center_X\", \"AreaShape_Center_Y\", \"AreaShape_MinorAxisLength\", \"AreaShape_MajorAxisLength\".\n",
    "This method will approximate the object as a circle based on the parameters above and the user can specify a cutoff percentage for which the object will be excluded. For instance, if the criteria is circle with 0.8, it means object where <80% of the area is in the frame will be excluded (ie 20% of object is outside of the frame).\n",
    "\n",
    "\n",
    "\n",
    "2. **Bounding Box**: for _CellProfiler versions >4.0_; the BoundingBoxMaximum and BoundingBoxMinimum coordinates were added in the v4.0 and can be used to remove objects whose coordinates intersect with image boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exclude border condition\n",
    "# criterion can be \"bbox\" or \"circle\"\n",
    "# if criterion is bbox: {\"criterion\":\"bbox\"}\n",
    "# if criterion is \"circle\", you can set percentage, e.g. {\"criterion\":\"circle\", \"percentage\":0.8} means take 80% of circle area\n",
    "exclude_borderobjs_conds = {\"criterion\":\"circle\", \"bymajor\":True, \"percentage\":0.7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st order: if the track goes through metapahse then use the last metaphase as time 0 \n",
    "2nd order: if the track starts with anaphase, then assign time point 1 \n",
    "\n",
    "\n",
    "**NOTE**: can change this alignment for reversine or prophase as reference time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rule for aligning time points\n",
    "align_conds={\"state_numbers\":[state_numbers[\"metaphase\"],state_numbers[\"anaphase\"]],\n",
    "             \"align_modes\":[\"last\",\"first\"],\n",
    "             \"shifts\":[0,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features will be added after alignment\n",
    "features = [\"ImageNumber\",\"ObjectNumber\",\"TrackObjects_Label\",\n",
    "            \"AreaShape_Area\",\n",
    "            \"AreaShape_Perimeter\",\n",
    "            \"AreaShape_FormFactor\",\n",
    "            \"Intensity_IntegratedIntensity_H2B_Smooth\",\n",
    "            \"Intensity_IntegratedIntensity_TRF1_Smooth\",\n",
    "            \"Intensity_MeanIntensity_H2B_Smooth\",\n",
    "            \"Intensity_MeanIntensity_TRF1_Smooth\",\n",
    "            \"Mean_Telomere_AreaShape_Area\",\n",
    "            \"Mean_Telomere_AreaShape_Perimeter\",\n",
    "            \"Mean_Telomere_Distance_Minimum_Nuclei\",\n",
    "            \"Mean_Telomere_Distance_Centroid_Nuclei\",\n",
    "            \"Mean_Telomere_Intensity_IntegratedIntensity_TRF1_Smooth\",\n",
    "            \"Children_Telomere_Count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process a specific file\n",
    "\n",
    "This is used to rerun or test a specific file. Set following 2 cells as \"Code\" if want to run or \"Raw NBConvert\" if don't want to.\n",
    "\n",
    "Otherwise, go to the next section."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set input file\n",
    "f = input_files[1]\n",
    "print(\"File:\\n\",f.split(base_input_path)[1])\n",
    "output_path = base_output_spath\n",
    "basestr = f.split(base_input_path)[1].split('.csv')[0]\n",
    "for name in basestr.split(os.sep):\n",
    "    if name != \"\":\n",
    "        output_path = os.path.join(output_path,name)\n",
    "print(\"Output_path:\\n\",output_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Processing...\")\n",
    "trackprocessor.process_data(f,output_path,features,G,exclude_borderobjs_conds=exclude_borderobjs_conds,align_conds=align_conds)\n",
    "print(\"Done!.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set the miminum number of timepoints for the tracks ie in this case we only use tracks with at least 5 timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_func(f,base_input_path,base_output_spath,\n",
    "                 features,transistion_graph,\n",
    "                 nrows_limit,min_nb_timepoints,\n",
    "                 exclude_borderobjs_conds,align_conds):\n",
    "    \n",
    "    # configure output path\n",
    "    output_path = base_output_spath\n",
    "    basestr = f.split(base_input_path)[1].split('.csv')[0]\n",
    "    for name in basestr.split(os.sep):\n",
    "        if name != \"\":\n",
    "            output_path = os.path.join(output_path,name)\n",
    "    \n",
    "#     try:\n",
    "    trackprocessor.process_data(f,output_path,features,transistion_graph,\n",
    "                          nrows_limit,min_nb_timepoints,\n",
    "                          exclude_borderobjs_conds,align_conds)\n",
    "#     except:\n",
    "#         return (False,basestr)\n",
    "    \n",
    "#     return (True,basestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_func = partial(compact_func,\n",
    "                       base_input_path=base_input_path,base_output_spath=base_output_spath,\n",
    "                       features=features,transistion_graph=G,\n",
    "                       nrows_limit=30,min_nb_timepoints=2,\n",
    "                       exclude_borderobjs_conds=exclude_borderobjs_conds,align_conds=align_conds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "M = np.zeros((3,3),dtype=np.bool)*1\n",
    "N = np.ones((3,3),dtype=np.bool)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "partial_func(input_files[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# process all files\n",
    "# note: use parallel computing instead (next section) to speed up computation\n",
    "for f in tqdm(input_files):\n",
    "    partial_func(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maxcpu = 10 # number of cpus (e.g. cores) to be used\n",
    "pool = pp.ProcessPool(min(len(input_files),maxcpu))\n",
    "print(\"nb. of allocated cpus:\",pool.ncpus)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "result = pool.map(partial_func,input_files)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Files failed to check:\")\n",
    "for res in result:\n",
    "    if res[0]==False:\n",
    "        print(res[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Files were sucessfully checked:\")\n",
    "for res in result:\n",
    "    if res[0]==True:\n",
    "        print(res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
